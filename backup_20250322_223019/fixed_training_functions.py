"""
Phi√™n b·∫£n ƒë√£ s·ª≠a l·ªói c·ªßa train_models v√† train_models_background trong app.py.
S·ª≠a l·ªói li√™n quan ƒë·∫øn session_state trong thread ri√™ng

H∆∞·ªõng d·∫´n:
1. Sao ch√©p to√†n b·ªô m√£ c√°c h√†m train_models_background() v√† train_models() v√†o app.py
2. Thay th·∫ø (ho·∫∑c b√¨nh lu·∫≠n) TO√ÄN B·ªò h√†m c≈© trong app.py 
3. T·∫°o th∆∞ m·ª•c utils n·∫øu ch∆∞a c√≥ v√† ƒë·∫£m b·∫£o c√≥ module thread_safe_logging.py
4. Kh·ªüi ƒë·ªông l·∫°i streamlit ƒë·ªÉ √°p d·ª•ng thay ƒë·ªïi
"""

def train_models_background():
    """H√†m hu·∫•n luy·ªán ch·∫°y trong thread ri√™ng bi·ªát"""
    from utils.thread_safe_logging import thread_safe_log
    
    try:
        thread_safe_log("B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán m√¥ h√¨nh AI trong thread ri√™ng...")
        thread_safe_log("L∆ØU √ù: ƒêang s·ª≠ d·ª•ng phi√™n b·∫£n an to√†n thread, tr√°nh truy c·∫≠p session_state")
        
        # QUAN TR·ªåNG: KH√îNG truy c·∫≠p st.session_state trong thread n√†y!
        # Thay v√¨ l·∫•y d·ªØ li·ªáu t·ª´ session_state, ch√∫ng ta s·∫Ω t·∫£i d·ªØ li·ªáu m·ªõi
        
        from utils.data_collector import create_data_collector
        from utils.data_processor import DataProcessor
        from models.model_trainer import ModelTrainer
        import config
        
        thread_safe_log("T·∫°o data collector...")
        data_collector = create_data_collector()
        
        thread_safe_log("T·∫°o data processor v√† model trainer...")
        data_processor = DataProcessor()
        model_trainer = ModelTrainer()
        
        thread_safe_log("Thu th·∫≠p d·ªØ li·ªáu l·ªãch s·ª≠...")
        if hasattr(config, 'HISTORICAL_START_DATE') and config.HISTORICAL_START_DATE:
            data = data_collector.collect_historical_data(
                timeframe=config.TIMEFRAMES["primary"],
                start_date=config.HISTORICAL_START_DATE
            )
        else:
            data = data_collector.collect_historical_data(
                timeframe=config.TIMEFRAMES["primary"],
                limit=config.LOOKBACK_PERIODS
            )
        
        if data is None or len(data) == 0:
            thread_safe_log("KH√îNG TH·ªÇ thu th·∫≠p d·ªØ li·ªáu cho hu·∫•n luy·ªán")
            return
            
        thread_safe_log(f"ƒê√£ thu th·∫≠p {len(data)} n·∫øn d·ªØ li·ªáu")
        
        # Ti·∫øp t·ª•c quy tr√¨nh hu·∫•n luy·ªán m√¥ h√¨nh v·ªõi d·ªØ li·ªáu m·ªõi thu th·∫≠p
        thread_safe_log("X·ª≠ l√Ω d·ªØ li·ªáu...")
        processed_data = data_processor.process_data(data)
        
        # Display feature information
        feature_count = len(processed_data.columns) - 1  # Exclude target column
        thread_safe_log(f"ƒê√£ t·∫°o {feature_count} ch·ªâ b√°o k·ªπ thu·∫≠t v√† t√≠nh nƒÉng")
        thread_safe_log(f"M·∫´u hu·∫•n luy·ªán: {len(processed_data)}")
        
        # Prepare data for models
        thread_safe_log("Chu·∫©n b·ªã d·ªØ li·ªáu chu·ªói cho LSTM v√† Transformer...")
        sequence_data = data_processor.prepare_sequence_data(processed_data)
        
        thread_safe_log("Chu·∫©n b·ªã d·ªØ li·ªáu h√¨nh ·∫£nh cho CNN...")
        image_data = data_processor.prepare_cnn_data(processed_data)
        
        # Hu·∫•n luy·ªán t·ª´ng m√¥ h√¨nh ri√™ng bi·ªát
        thread_safe_log("Hu·∫•n luy·ªán m√¥ h√¨nh LSTM...")
        lstm_model, lstm_history = model_trainer.train_lstm(sequence_data)
        
        thread_safe_log("Hu·∫•n luy·ªán m√¥ h√¨nh Transformer...")
        transformer_model, transformer_history = model_trainer.train_transformer(sequence_data)
        
        thread_safe_log("Hu·∫•n luy·ªán m√¥ h√¨nh CNN...")
        cnn_model, cnn_history = model_trainer.train_cnn(image_data)
        
        thread_safe_log("Hu·∫•n luy·ªán m√¥ h√¨nh Similarity l·ªãch s·ª≠...")
        historical_model, _ = model_trainer.train_historical_similarity(sequence_data)
        
        thread_safe_log("Hu·∫•n luy·ªán m√¥ h√¨nh Meta-Learner...")
        meta_model, _ = model_trainer.train_meta_learner(sequence_data, image_data)
        
        thread_safe_log("Hu·∫•n luy·ªán th√†nh c√¥ng t·∫•t c·∫£ c√°c m√¥ h√¨nh!")
        
        # L∆∞u tr·∫°ng th√°i hu·∫•n luy·ªán v√†o file
        try:
            import json
            from datetime import datetime
            
            models = {
                'lstm': lstm_model,
                'transformer': transformer_model,
                'cnn': cnn_model,
                'historical_similarity': historical_model,
                'meta_learner': meta_model
            }
            
            # L∆∞u models v√†o file
            import os
            import pickle
            
            if not os.path.exists("saved_models"):
                os.makedirs("saved_models")
                
            with open("saved_models/models.pkl", "wb") as f:
                pickle.dump(models, f)
                
            # L∆∞u metadata v·ªÅ qu√° tr√¨nh hu·∫•n luy·ªán
            training_status = {
                'last_training_time': datetime.now().isoformat(),
                'data_points': len(data),
                'model_version': config.MODEL_VERSION if hasattr(config, 'MODEL_VERSION') else "1.0.0",
                'training_complete': True
            }
            
            with open("saved_models/training_status.json", "w") as f:
                json.dump(training_status, f)
                
            thread_safe_log("ƒê√£ l∆∞u t·∫•t c·∫£ m√¥ h√¨nh v√†o saved_models/models.pkl")
        except Exception as e:
            thread_safe_log(f"L·ªói khi l∆∞u m√¥ h√¨nh: {str(e)}")
            
    except Exception as e:
        thread_safe_log(f"‚ùå L·ªói trong qu√° tr√¨nh hu·∫•n luy·ªán: {str(e)}")
        import traceback
        thread_safe_log(f"Chi ti·∫øt l·ªói: {traceback.format_exc()}")

def train_models():
    """Train all prediction models in a background thread"""
    import os
    import sys
    import time
    import threading
    from datetime import datetime
    import streamlit as st
    
    if not st.session_state.initialized or st.session_state.latest_data is None:
        st.warning("H·ªá th·ªëng ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o ho·∫∑c kh√¥ng c√≥ d·ªØ li·ªáu")
        show_toast("H·ªá th·ªëng ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o ho·∫∑c kh√¥ng c√≥ d·ªØ li·ªáu", "warning")
        return False
    
    # ƒê·∫£m b·∫£o th∆∞ m·ª•c utils/thread_safe_logging.py t·ªìn t·∫°i
    try:
        from utils.thread_safe_logging import thread_safe_log, read_logs_from_file
    except ImportError:
        # N·∫øu kh√¥ng c√≥, t·∫°o module thread-safe logging
        if not os.path.exists("utils"):
            os.makedirs("utils")
            
        with open("utils/thread_safe_logging.py", "w") as f:
            f.write("""
\"\"\"
Thread-safe logging functions for AI Trading System
\"\"\"
import os
import sys
import time
import threading
from datetime import datetime

_log_lock = threading.Lock()

def log_to_file(message, log_file="training_logs.txt"):
    \"\"\"Thread-safe function to log messages to a file\"\"\"
    with _log_lock:
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        with open(log_file, "a") as f:
            f.write(f"{timestamp} - {message}\\n")
            f.flush()

def log_to_console(message):
    \"\"\"Thread-safe function to log messages to console\"\"\"
    with _log_lock:
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        print(f"{timestamp} - {message}")
        sys.stdout.flush()

def thread_safe_log(message, log_file="training_logs.txt"):
    \"\"\"Combined logging function that logs to both file and console\"\"\"
    log_to_file(message, log_file)
    log_to_console(message)

def read_logs_from_file(log_file="training_logs.txt", max_lines=100):
    \"\"\"Read log entries from file with a maximum number of lines\"\"\"
    if not os.path.exists(log_file):
        return []
        
    with open(log_file, "r") as f:
        lines = f.readlines()
        
    # Return last N lines (most recent)
    return lines[-max_lines:]
""")
        
        # T·∫°o file log tr·ªëng
        with open("training_logs.txt", "w") as f:
            f.write("")
            
        # Import l·∫°i sau khi t·∫°o
        from utils.thread_safe_logging import thread_safe_log, read_logs_from_file
    
    # Th√¥ng b√°o cho ng∆∞·ªùi d√πng
    progress_placeholder = st.empty()
    progress_placeholder.info("Qu√° tr√¨nh hu·∫•n luy·ªán b·∫Øt ƒë·∫ßu trong n·ªÅn. B·∫°n c√≥ th·ªÉ ti·∫øp t·ª•c s·ª≠ d·ª•ng ·ª©ng d·ª•ng.")
    
    # Progress bar
    progress_bar = st.progress(0)
    
    # Kh·ªüi t·∫°o session state n·∫øu ch∆∞a c√≥
    if 'training_log_messages' not in st.session_state:
        st.session_state.training_log_messages = []
        
    if 'log_messages' not in st.session_state:
        st.session_state.log_messages = []
    
    # Th√™m message kh·ªüi ƒë·ªông hu·∫•n luy·ªán
    timestamp = datetime.now().strftime("%H:%M:%S")
    log_message = f"{timestamp} - üß† B·∫Øt ƒë·∫ßu qu√° tr√¨nh hu·∫•n luy·ªán AI trong n·ªÅn..."
    st.session_state.log_messages.append(log_message)
    st.session_state.training_log_messages.append(log_message)
    
    # Ghi log v√†o file
    thread_safe_log("B·∫Øt ƒë·∫ßu qu√° tr√¨nh hu·∫•n luy·ªán m√¥ h√¨nh AI")
    
    # B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán trong thread
    training_thread = threading.Thread(target=train_models_background)
    training_thread.daemon = True  # Thread s·∫Ω t·ª± ƒë√≥ng khi ch∆∞∆°ng tr√¨nh ch√≠nh k·∫øt th√∫c
    training_thread.start()
    
    # C·∫≠p nh·∫≠t UI
    def update_progress():
        placeholder = st.empty()
        log_container = placeholder.container()
        
        while training_thread.is_alive():
            # ƒê·ªçc logs t·ª´ file
            logs = read_logs_from_file("training_logs.txt", 20)
            
            # Hi·ªÉn th·ªã logs
            if logs:
                log_display = "\n".join(logs)
                log_container.text_area("Ti·∫øn tr√¨nh hu·∫•n luy·ªán:", log_display, height=300)
                
                # C·∫≠p nh·∫≠t progress bar
                progress = 0
                for log in logs:
                    if "LSTM" in log:
                        progress = max(progress, 20)
                    elif "Transformer" in log:
                        progress = max(progress, 40)
                    elif "CNN" in log:
                        progress = max(progress, 60)
                    elif "Similarity" in log:
                        progress = max(progress, 80)
                    elif "Meta-Learner" in log:
                        progress = max(progress, 90)
                    elif "th√†nh c√¥ng" in log or "ƒê√£ l∆∞u" in log:
                        progress = 100
                
                progress_bar.progress(progress)
                
                # Hi·ªÉn th·ªã toast cho th√¥ng b√°o quan tr·ªçng
                last_log = logs[-1].lower() if logs else ""
                if "l·ªói" in last_log:
                    show_toast("C√≥ l·ªói trong qu√° tr√¨nh hu·∫•n luy·ªán", "error")
                elif "th√†nh c√¥ng" in last_log:
                    show_toast("Hu·∫•n luy·ªán m√¥ h√¨nh th√†nh c√¥ng!", "success")
            
            # T·∫°m d·ª´ng 2 gi√¢y tr∆∞·ªõc khi c·∫≠p nh·∫≠t l·∫°i
            time.sleep(2)
        
        # Khi thread k·∫øt th√∫c, hi·ªÉn th·ªã th√¥ng b√°o ho√†n t·∫•t
        final_logs = read_logs_from_file("training_logs.txt", 20)
        success = any("th√†nh c√¥ng" in log.lower() for log in final_logs)
        
        if success:
            progress_bar.progress(100)
            progress_placeholder.success("Hu·∫•n luy·ªán m√¥ h√¨nh th√†nh c√¥ng!")
        else:
            progress_placeholder.error("Hu·∫•n luy·ªán m√¥ h√¨nh th·∫•t b·∫°i. Xem logs ƒë·ªÉ bi·∫øt chi ti·∫øt.")
    
    # Ch·∫°y update_progress trong m·ªôt thread ri√™ng bi·ªát
    update_thread = threading.Thread(target=update_progress)
    update_thread.daemon = True
    update_thread.start()
    
    return True