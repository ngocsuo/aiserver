#!/usr/bin/env python3
"""
Script tr·ª±c ti·∫øp ƒë·ªÉ k√≠ch ho·∫°t hu·∫•n luy·ªán m√¥ h√¨nh kh√¥ng th√¥ng qua Streamlit
"""
import os
import sys
import time
import logging
from datetime import datetime

# C·∫•u h√¨nh logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('direct_training.log')
    ]
)
logger = logging.getLogger("DirectTrainer")

# Import c√°c module c·∫ßn thi·∫øt
import pandas as pd
import numpy as np

# Th√™m tr·ª±c ti·∫øp h√†m truy xu·∫•t th√†nh ph·∫ßn hu·∫•n luy·ªán
def train_directly():
    """Hu·∫•n luy·ªán tr·ª±c ti·∫øp c√°c m√¥ h√¨nh m√† kh√¥ng th√¥ng qua Streamlit"""
    logger.info("B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán tr·ª±c ti·∫øp...")
    
    # Import c√°c module c·∫ßn thi·∫øt
    from utils.data_collector import create_data_collector
    from utils.data_processor import DataProcessor
    from models.model_trainer import ModelTrainer
    import config
    
    # Ghi nh·∫≠t k√Ω hu·∫•n luy·ªán
    def log_message(message):
        """Ghi nh·∫≠t k√Ω hu·∫•n luy·ªán v√†o file"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        with open("training_logs.txt", "a") as f:
            f.write(f"{timestamp} - {message}\n")
        logger.info(message)
    
    try:
        log_message("üöÄ B·∫ÆT ƒê·∫¶U HU·∫§N LUY·ªÜN TR·ª∞C TI·∫æP")
        
        # T·∫°o c√°c ƒë·ªëi t∆∞·ª£ng c·∫ßn thi·∫øt
        log_message("T·∫°o data collector, processor v√† model trainer...")
        data_collector = create_data_collector()
        data_processor = DataProcessor()
        model_trainer = ModelTrainer()
        
        # Thu th·∫≠p d·ªØ li·ªáu
        log_message("Thu th·∫≠p d·ªØ li·ªáu l·ªãch s·ª≠...")
        if hasattr(config, 'HISTORICAL_START_DATE') and config.HISTORICAL_START_DATE:
            log_message(f"S·ª≠ d·ª•ng ng√†y b·∫Øt ƒë·∫ßu: {config.HISTORICAL_START_DATE}")
            data = data_collector.collect_historical_data(
                timeframe=config.PRIMARY_TIMEFRAME,
                start_date=config.HISTORICAL_START_DATE
            )
        else:
            log_message(f"S·ª≠ d·ª•ng {config.LOOKBACK_PERIODS} n·∫øn g·∫ßn nh·∫•t")
            data = data_collector.collect_historical_data(
                timeframe=config.PRIMARY_TIMEFRAME,
                limit=config.LOOKBACK_PERIODS
            )
        
        if data is None or len(data) == 0:
            log_message("‚ùå KH√îNG TH·ªÇ thu th·∫≠p d·ªØ li·ªáu cho hu·∫•n luy·ªán")
            return False
            
        log_message(f"‚úÖ ƒê√£ thu th·∫≠p {len(data)} n·∫øn d·ªØ li·ªáu")
        
        # X·ª≠ l√Ω d·ªØ li·ªáu
        log_message("X·ª≠ l√Ω d·ªØ li·ªáu...")
        processed_data = data_processor.process_data(data)
        log_message(f"‚úÖ ƒê√£ x·ª≠ l√Ω {len(processed_data)} m·∫´u d·ªØ li·ªáu")
        
        # Chu·∫©n b·ªã d·ªØ li·ªáu cho c√°c m√¥ h√¨nh kh√°c nhau
        log_message("Chu·∫©n b·ªã d·ªØ li·ªáu hu·∫•n luy·ªán...")
        sequence_data = data_processor.prepare_sequence_data(processed_data)
        image_data = data_processor.prepare_image_data(processed_data)
        log_message("‚úÖ ƒê√£ chu·∫©n b·ªã d·ªØ li·ªáu cho c√°c m√¥ h√¨nh")
        
        # Hu·∫•n luy·ªán t·∫•t c·∫£ c√°c m√¥ h√¨nh
        log_message("üîÑ B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán c√°c m√¥ h√¨nh...")
        
        # ƒê·∫øm s·ªë ƒë·∫∑c tr∆∞ng
        feature_count = processed_data.shape[1] - 1  # Tr·ª´ c·ªôt target
        
        # Hu·∫•n luy·ªán m√¥ h√¨nh LSTM
        log_message("Hu·∫•n luy·ªán m√¥ h√¨nh LSTM...")
        lstm_model = model_trainer.train_lstm(sequence_data)
        log_message("‚úÖ ƒê√£ hu·∫•n luy·ªán m√¥ h√¨nh LSTM")
        
        # Hu·∫•n luy·ªán m√¥ h√¨nh Transformer
        log_message("Hu·∫•n luy·ªán m√¥ h√¨nh Transformer...")
        transformer_model = model_trainer.train_transformer(sequence_data)
        log_message("‚úÖ ƒê√£ hu·∫•n luy·ªán m√¥ h√¨nh Transformer")
        
        # Hu·∫•n luy·ªán m√¥ h√¨nh CNN
        log_message("Hu·∫•n luy·ªán m√¥ h√¨nh CNN...")
        cnn_model = model_trainer.train_cnn(image_data)
        log_message("‚úÖ ƒê√£ hu·∫•n luy·ªán m√¥ h√¨nh CNN")
        
        # Hu·∫•n luy·ªán m√¥ h√¨nh Historical Similarity
        log_message("Hu·∫•n luy·ªán m√¥ h√¨nh Historical Similarity...")
        historical_model = model_trainer.train_historical_similarity(sequence_data)
        log_message("‚úÖ ƒê√£ hu·∫•n luy·ªán m√¥ h√¨nh Historical Similarity")
        
        # Hu·∫•n luy·ªán Meta-Learner
        log_message("Hu·∫•n luy·ªán m√¥ h√¨nh Meta-Learner...")
        meta_model = model_trainer.train_meta_learner(sequence_data, image_data)
        log_message("‚úÖ ƒê√£ hu·∫•n luy·ªán m√¥ h√¨nh Meta-Learner")
        
        log_message("‚úÖ Hu·∫•n luy·ªán th√†nh c√¥ng t·∫•t c·∫£ c√°c m√¥ h√¨nh!")
        
        # L∆∞u models v√†o file
        models = {
            'lstm': lstm_model,
            'transformer': transformer_model,
            'cnn': cnn_model,
            'historical_similarity': historical_model,
            'meta_learner': meta_model
        }
        
        # L∆∞u models v√†o th∆∞ m·ª•c
        import os
        import pickle
        import json
        
        if not os.path.exists("saved_models"):
            os.makedirs("saved_models")
            
        with open("saved_models/models.pkl", "wb") as f:
            pickle.dump(models, f)
            
        # L∆∞u metadata v·ªÅ qu√° tr√¨nh hu·∫•n luy·ªán
        training_status = {
            'last_training_time': datetime.now().isoformat(),
            'data_points': len(data),
            'feature_count': feature_count,
            'training_samples': len(processed_data),
            'model_version': config.MODEL_VERSION if hasattr(config, 'MODEL_VERSION') else "1.0.0",
            'training_complete': True
        }
        
        with open("saved_models/training_status.json", "w") as f:
            json.dump(training_status, f)
            
        log_message("‚úÖ ƒê√£ l∆∞u t·∫•t c·∫£ m√¥ h√¨nh v√†o saved_models/models.pkl")
        log_message("‚úÖ ƒê√É HO√ÄN TH√ÄNH QU√Å TR√åNH HU·∫§N LUY·ªÜN TR·ª∞C TI·∫æP")
        
        return True
            
    except Exception as e:
        log_message(f"‚ùå L·ªói khi hu·∫•n luy·ªán: {str(e)}")
        import traceback
        log_message(f"Chi ti·∫øt l·ªói: {traceback.format_exc()}")
        return False

if __name__ == "__main__":
    print("=========================================")
    print("KH·ªûI ƒê·ªòNG HU·∫§N LUY·ªÜN M√î H√åNH TR·ª∞C TI·∫æP")
    print("=========================================")
    
    # Ghi nh·∫≠t k√Ω kh·ªüi ƒë·ªông
    with open("training_logs.txt", "a") as f:
        f.write(f"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} - üöÄ B·∫ÆT ƒê·∫¶U HU·∫§N LUY·ªÜN TR·ª∞C TI·∫æP T·ª™ SCRIPT\n")
    
    # Hu·∫•n luy·ªán
    result = train_directly()
    
    # Hi·ªÉn th·ªã k·∫øt qu·∫£
    if result:
        print("‚úÖ HU·∫§N LUY·ªÜN HO√ÄN T·∫§T TH√ÄNH C√îNG!")
    else:
        print("‚ùå HU·∫§N LUY·ªÜN TH·∫§T B·∫†I!")
        
    print("=========================================")
