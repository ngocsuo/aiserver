"""
Phi√™n b·∫£n s·ª≠a ƒë·ªïi c·ªßa h√†m train_models() ph√π h·ª£p v·ªõi c·∫•u tr√∫c hi·ªán t·∫°i
"""

def train_models():
    """Train all prediction models in a background thread"""
    import os
    import threading
    import datetime
    import streamlit as st
    from utils.thread_safe_logging import thread_safe_log
    
    # T·∫°o file training_logs.txt n·∫øu ch∆∞a t·ªìn t·∫°i
    if not os.path.exists("training_logs.txt"):
        with open("training_logs.txt", "w") as f:
            f.write("# Training logs started\n")
    
    # Th√¥ng b√°o cho ng∆∞·ªùi d√πng
    progress_placeholder = st.empty()
    progress_placeholder.info("Qu√° tr√¨nh hu·∫•n luy·ªán b·∫Øt ƒë·∫ßu trong n·ªÅn. B·∫°n c√≥ th·ªÉ ti·∫øp t·ª•c s·ª≠ d·ª•ng ·ª©ng d·ª•ng.")
    
    # Progress bar
    progress_bar = st.progress(0)
    
    # Ki·ªÉm tra xem c√≥ th√¥ng s·ªë t√πy ch·ªânh kh√¥ng
    custom_params = st.session_state.get('custom_training_params', None)
    if custom_params:
        thread_safe_log(f"S·ª≠ d·ª•ng c√†i ƒë·∫∑t t√πy ch·ªânh: {custom_params['timeframe']}, {custom_params['range']}, ng∆∞·ª°ng {custom_params['threshold']}%, {custom_params['epochs']} epochs")
        if hasattr(st, 'toast'):
            st.toast(f"Hu·∫•n luy·ªán v·ªõi c√†i ƒë·∫∑t t√πy ch·ªânh: {custom_params['timeframe']}, {custom_params['epochs']} epochs", icon="üîß")
    
    # Ghi log v√†o file
    thread_safe_log("B·∫Øt ƒë·∫ßu qu√° tr√¨nh hu·∫•n luy·ªán m√¥ h√¨nh...")
    
    # T·∫°o thread hu·∫•n luy·ªán
    training_thread = threading.Thread(
        target=train_models_background,
        name="train_models_background"
    )
    training_thread.daemon = True
    training_thread.start()
    
    # Hi·ªÉn th·ªã th√¥ng b√°o cho user
    st.success("ƒê√£ b·∫Øt ƒë·∫ßu hu·∫•n luy·ªán m√¥ h√¨nh trong n·ªÅn. Ki·ªÉm tra logs ƒë·ªÉ theo d√µi ti·∫øn tr√¨nh.")
    
    # X√≥a c√°c th√†nh ph·∫ßn UI hi·ªÉn th·ªã l√™n
    if 'progress_bar' in locals():
        progress_bar.empty()
    if 'progress_placeholder' in locals():
        progress_placeholder.empty()
    
    return True

def train_models_background():
    """H√†m hu·∫•n luy·ªán ch·∫°y trong thread ri√™ng bi·ªát"""
    from utils.thread_safe_logging import thread_safe_log
    import datetime
    
    try:
        thread_safe_log("B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán m√¥ h√¨nh AI trong thread ri√™ng...")
        thread_safe_log("L∆ØU √ù: ƒêang s·ª≠ d·ª•ng phi√™n b·∫£n an to√†n thread, tr√°nh truy c·∫≠p session_state")
        
        # QUAN TR·ªåNG: KH√îNG truy c·∫≠p st.session_state trong thread n√†y!
        # Thay v√¨ l·∫•y d·ªØ li·ªáu t·ª´ session_state, ch√∫ng ta s·∫Ω t·∫£i d·ªØ li·ªáu m·ªõi
        
        from utils.data_collector import create_data_collector
        from utils.data_processor import DataProcessor
        from models.model_trainer import ModelTrainer
        import config
        
        thread_safe_log("B∆∞·ªõc 1/5: T·∫°o data collector...")
        data_collector = create_data_collector()
        
        thread_safe_log("T·∫°o data processor v√† model trainer...")
        data_processor = DataProcessor()
        model_trainer = ModelTrainer()
        
        thread_safe_log("B∆∞·ªõc 2/5: Thu th·∫≠p d·ªØ li·ªáu l·ªãch s·ª≠...")
        if hasattr(config, 'HISTORICAL_START_DATE') and config.HISTORICAL_START_DATE:
            data = data_collector.collect_historical_data(
                timeframe=config.TIMEFRAMES["primary"],
                start_date=config.HISTORICAL_START_DATE
            )
        else:
            data = data_collector.collect_historical_data(
                timeframe=config.TIMEFRAMES["primary"],
                limit=config.LOOKBACK_PERIODS
            )
        
        if data is None or len(data) == 0:
            thread_safe_log("KH√îNG TH·ªÇ thu th·∫≠p d·ªØ li·ªáu cho hu·∫•n luy·ªán")
            return
            
        thread_safe_log(f"ƒê√£ thu th·∫≠p {len(data)} n·∫øn d·ªØ li·ªáu")
        
        # Ti·∫øp t·ª•c quy tr√¨nh hu·∫•n luy·ªán m√¥ h√¨nh v·ªõi d·ªØ li·ªáu m·ªõi thu th·∫≠p
        thread_safe_log("B∆∞·ªõc 3/5: X·ª≠ l√Ω d·ªØ li·ªáu...")
        processed_data = data_processor.process_data(data)
        
        # Display feature information
        feature_count = len(processed_data.columns) - 1  # Exclude target column
        thread_safe_log(f"ƒê√£ t·∫°o {feature_count} ch·ªâ b√°o k·ªπ thu·∫≠t v√† t√≠nh nƒÉng")
        thread_safe_log(f"M·∫´u hu·∫•n luy·ªán: {len(processed_data)}")
        
        # Prepare data for models
        thread_safe_log("Chu·∫©n b·ªã d·ªØ li·ªáu chu·ªói cho LSTM v√† Transformer...")
        sequence_data = data_processor.prepare_sequence_data(processed_data)
        
        thread_safe_log("Chu·∫©n b·ªã d·ªØ li·ªáu h√¨nh ·∫£nh cho CNN...")
        image_data = data_processor.prepare_cnn_data(processed_data)
        
        # Hu·∫•n luy·ªán t·ª´ng m√¥ h√¨nh ri√™ng bi·ªát
        thread_safe_log("B∆∞·ªõc 4/5: Hu·∫•n luy·ªán m√¥ h√¨nh LSTM...")
        lstm_model, lstm_history = model_trainer.train_lstm(sequence_data)
        
        thread_safe_log("Hu·∫•n luy·ªán m√¥ h√¨nh Transformer...")
        transformer_model, transformer_history = model_trainer.train_transformer(sequence_data)
        
        thread_safe_log("Hu·∫•n luy·ªán m√¥ h√¨nh CNN...")
        cnn_model, cnn_history = model_trainer.train_cnn(image_data)
        
        thread_safe_log("Hu·∫•n luy·ªán m√¥ h√¨nh Similarity l·ªãch s·ª≠...")
        historical_model, _ = model_trainer.train_historical_similarity(sequence_data)
        
        thread_safe_log("B∆∞·ªõc 5/5: Hu·∫•n luy·ªán m√¥ h√¨nh Meta-Learner...")
        meta_model, _ = model_trainer.train_meta_learner(sequence_data, image_data)
        
        thread_safe_log("Hu·∫•n luy·ªán th√†nh c√¥ng t·∫•t c·∫£ c√°c m√¥ h√¨nh!")
        
        # L∆∞u tr·∫°ng th√°i hu·∫•n luy·ªán v√†o file
        try:
            import json
            training_result = {
                "success": True,
                "timestamp": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "message": "Hu·∫•n luy·ªán th√†nh c√¥ng t·∫•t c·∫£ c√°c m√¥ h√¨nh"
            }
            with open('training_result.json', 'w') as f:
                json.dump(training_result, f)
                
            # Th√¥ng b√°o ƒë√£ hu·∫•n luy·ªán th√†nh c√¥ng - set flag cho main thread
            with open('training_completed.txt', 'w') as f:
                f.write('success')
        except Exception as e:
            thread_safe_log(f"L·ªói l∆∞u k·∫øt qu·∫£ hu·∫•n luy·ªán: {str(e)}")
                
    except Exception as e:
        from utils.thread_safe_logging import thread_safe_log
        thread_safe_log(f"L·ªñI trong qu√° tr√¨nh hu·∫•n luy·ªán: {str(e)}")
        
        # L∆∞u th√¥ng tin l·ªói v√†o file
        try:
            import json
            training_result = {
                "success": False,
                "timestamp": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "error": str(e)
            }
            with open('training_result.json', 'w') as f:
                json.dump(training_result, f)
                
            # Th√¥ng b√°o l·ªói cho main thread
            with open('training_completed.txt', 'w') as f:
                f.write('error')
        except Exception:
            pass