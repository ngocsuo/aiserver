# H∆∞·ªõng d·∫´n s·ª≠a l·ªói cho tri·ªÉn khai tr√™n server

## T√≥m t·∫Øt c√°c v·∫•n ƒë·ªÅ ƒë√£ ph√°t hi·ªán:

1. **L·ªói thread-safety trong qu√° tr√¨nh hu·∫•n luy·ªán:** Kh√¥ng th·ªÉ truy c·∫≠p st.session_state t·ª´ thread kh√°c
2. **L·ªói pandas style.map:** Phi√™n b·∫£n pandas m·ªõi kh√¥ng c√≥ ph∆∞∆°ng th·ª©c style.map
3. **L·ªói k·∫øt n·ªëi Binance API:** Geographic restriction - s·∫Ω ƒë∆∞·ª£c gi·∫£i quy·∫øt khi tri·ªÉn khai ·ªü Vi·ªát Nam

## Gi·∫£i ph√°p cho t·∫•t c·∫£ c√°c v·∫•n ƒë·ªÅ:

### 1. S·ª≠a l·ªói pandas style.map (d√≤ng 2194)

T√¨m d√≤ng:
```python
styled_df = recent_preds.style.map(style_trend, subset=['trend'])
```

Thay b·∫±ng:
```python
try:
    # Th·ª≠ c√°ch 1: s·ª≠ d·ª•ng style.applymap (pandas c≈©)
    styled_df = recent_preds.style.applymap(style_trend, subset=['trend'])
except AttributeError:
    # Th·ª≠ c√°ch 2: s·ª≠ d·ª•ng style.apply v·ªõi h√†m kh√°c
    def highlight_trend(s):
        return ['background-color: green; color: white' if x == 'LONG' 
                else 'background-color: red; color: white' if x == 'SHORT'
                else 'background-color: gray; color: white' for x in s]
    
    styled_df = recent_preds.style.apply(highlight_trend, subset=['trend'])
```

### 2. S·ª≠a l·ªói thread-safety trong hu·∫•n luy·ªán:

#### B∆∞·ªõc 1: T·∫°o file thread_safe_logging.py

```python
"""
Thread-safe logging functions for AI Trading System
"""
import threading
import datetime
import os

# Thread-safe lock for logging
log_lock = threading.Lock()

def log_to_file(message, log_file="training_logs.txt"):
    """Thread-safe function to log messages to a file"""
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    log_entry = f"{timestamp} - {message}\n"
    
    with log_lock:
        try:
            with open(log_file, "a") as f:
                f.write(log_entry)
        except Exception as e:
            print(f"Error writing to log file: {e}")

def log_to_console(message):
    """Thread-safe function to log messages to console"""
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    log_entry = f"{timestamp} - {message}"
    
    with log_lock:
        print(log_entry)

def thread_safe_log(message, log_file="training_logs.txt"):
    """Combined logging function that logs to both file and console"""
    log_to_file(message, log_file)
    log_to_console(message)

def read_logs_from_file(log_file="training_logs.txt", max_lines=100):
    """Read log entries from file with a maximum number of lines"""
    if not os.path.exists(log_file):
        return []
        
    try:
        with open(log_file, "r") as f:
            # Read last max_lines lines
            lines = f.readlines()
            return lines[-max_lines:] if len(lines) > max_lines else lines
    except Exception as e:
        print(f"Error reading log file: {e}")
        return []
```

#### B∆∞·ªõc 2: S·ª≠a h√†m train_models:

```python
def train_models():
    """Train all prediction models in a background thread"""
    import os
    import json
    import threading
    from utils.thread_safe_logging import thread_safe_log
    
    # T·∫°o file training_logs.txt n·∫øu ch∆∞a t·ªìn t·∫°i
    if not os.path.exists("training_logs.txt"):
        with open("training_logs.txt", "w") as f:
            f.write("# Training logs started\n")
    
    # L·∫•y d·ªØ li·ªáu t·ª´ session_state v√† chu·∫©n b·ªã truy·ªÅn v√†o thread
    if not hasattr(st.session_state, 'latest_data') or st.session_state.latest_data is None:
        st.error("Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ hu·∫•n luy·ªán. Vui l√≤ng thu th·∫≠p d·ªØ li·ªáu tr∆∞·ªõc.")
        return False
    
    # L·∫•y c√°c d·ªØ li·ªáu c·∫ßn thi·∫øt t·ª´ session_state
    latest_data = st.session_state.latest_data.copy() if hasattr(st.session_state, 'latest_data') else None
    data_processor = st.session_state.data_processor if hasattr(st.session_state, 'data_processor') else None
    model_trainer = st.session_state.model_trainer if hasattr(st.session_state, 'model_trainer') else None
    custom_params = st.session_state.get('custom_training_params', None)
    
    # Ki·ªÉm tra d·ªØ li·ªáu ƒë·ªß ƒë·ªÉ hu·∫•n luy·ªán kh√¥ng
    if latest_data is None or data_processor is None or model_trainer is None:
        thread_safe_log("Kh√¥ng ƒë·ªß d·ªØ li·ªáu ho·∫∑c th√†nh ph·∫ßn c·∫ßn thi·∫øt ƒë·ªÉ hu·∫•n luy·ªán")
        st.error("Kh√¥ng ƒë·ªß d·ªØ li·ªáu ho·∫∑c th√†nh ph·∫ßn c·∫ßn thi·∫øt ƒë·ªÉ hu·∫•n luy·ªán")
        return False
    
    # Truy·ªÅn d·ªØ li·ªáu v√†o thread qua tham s·ªë
    thread_safe_log("Kh·ªüi ƒë·ªông qu√° tr√¨nh hu·∫•n luy·ªán AI...")
    training_thread = threading.Thread(
        target=train_models_background,
        args=(latest_data, data_processor, model_trainer, custom_params)
    )
    training_thread.daemon = True
    training_thread.start()
    
    return True
```

#### B∆∞·ªõc 3: S·ª≠a h√†m train_models_background:

```python
def train_models_background(latest_data, data_processor, model_trainer, custom_params=None):
    """H√†m hu·∫•n luy·ªán ch·∫°y trong thread ri√™ng bi·ªát"""
    import datetime
    import json
    import os
    import config
    from utils.thread_safe_logging import thread_safe_log
    
    try:
        # S·ª≠ d·ª•ng thread_safe_log thay v√¨ update_log
        thread_safe_log("B·∫Øt ƒë·∫ßu qu√° tr√¨nh hu·∫•n luy·ªán m√¥ h√¨nh AI trong n·ªÅn...")
        thread_safe_log("B∆∞·ªõc 1/5: Chu·∫©n b·ªã d·ªØ li·ªáu ETHUSDT...")
        
        # B√¢y gi·ªù s·ª≠ d·ª•ng c√°c d·ªØ li·ªáu ƒë∆∞·ª£c truy·ªÅn v√†o thay v√¨ truy c·∫≠p session_state
        data = latest_data
        thread_safe_log(f"S·ªë ƒëi·ªÉm d·ªØ li·ªáu: {len(data)} n·∫øn")
        thread_safe_log(f"Khung th·ªùi gian: {data.name if hasattr(data, 'name') else config.TIMEFRAMES['primary']}")
        thread_safe_log(f"Ph·∫°m vi ng√†y: {data.index.min()} ƒë·∫øn {data.index.max()}")
        
        # Step 2: Preprocess data
        thread_safe_log("B∆∞·ªõc 2/5: Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu v√† t√≠nh to√°n ch·ªâ b√°o k·ªπ thu·∫≠t...")
        processed_data = data_processor.process_data(data)
        
        # Display feature information
        feature_count = len(processed_data.columns) - 1  # Exclude target column
        thread_safe_log(f"ƒê√£ t·∫°o {feature_count} ch·ªâ b√°o k·ªπ thu·∫≠t v√† t√≠nh nƒÉng")
        thread_safe_log(f"M·∫´u hu·∫•n luy·ªán: {len(processed_data)} (sau khi lo·∫°i b·ªè gi√° tr·ªã NaN)")
        
        # Display class distribution
        if 'target_class' in processed_data.columns:
            class_dist = processed_data['target_class'].value_counts()
            thread_safe_log(f"Ph√¢n ph·ªëi l·ªõp: SHORT={class_dist.get(0, 0)}, NEUTRAL={class_dist.get(1, 0)}, LONG={class_dist.get(2, 0)}")
        
        # Step 3: Prepare sequence and image data
        thread_safe_log("B∆∞·ªõc 3/5: Chu·∫©n b·ªã d·ªØ li·ªáu chu·ªói cho m√¥ h√¨nh LSTM v√† Transformer...")
        sequence_data = data_processor.prepare_sequence_data(processed_data)
        
        thread_safe_log("Chu·∫©n b·ªã d·ªØ li·ªáu h√¨nh ·∫£nh cho m√¥ h√¨nh CNN...")
        image_data = data_processor.prepare_cnn_data(processed_data)
        
        # Step 4: Train all models
        thread_safe_log("B∆∞·ªõc 4/5: Hu·∫•n luy·ªán m√¥ h√¨nh LSTM...")
        lstm_model, lstm_history = model_trainer.train_lstm(sequence_data)
        thread_safe_log(f"M√¥ h√¨nh LSTM ƒë√£ hu·∫•n luy·ªán v·ªõi ƒë·ªô ch√≠nh x√°c: {lstm_history.get('val_accuracy', [-1])[-1]:.4f}")
        
        thread_safe_log("Hu·∫•n luy·ªán m√¥ h√¨nh Transformer...")
        transformer_model, transformer_history = model_trainer.train_transformer(sequence_data)
        thread_safe_log(f"M√¥ h√¨nh Transformer ƒë√£ hu·∫•n luy·ªán v·ªõi ƒë·ªô ch√≠nh x√°c: {transformer_history.get('val_accuracy', [-1])[-1]:.4f}")
        
        thread_safe_log("Hu·∫•n luy·ªán m√¥ h√¨nh CNN...")
        cnn_model, cnn_history = model_trainer.train_cnn(image_data)
        thread_safe_log(f"M√¥ h√¨nh CNN ƒë√£ hu·∫•n luy·ªán v·ªõi ƒë·ªô ch√≠nh x√°c: {cnn_history.get('val_accuracy', [-1])[-1]:.4f}")
        
        thread_safe_log("Hu·∫•n luy·ªán m√¥ h√¨nh Similarity l·ªãch s·ª≠...")
        historical_model, _ = model_trainer.train_historical_similarity(sequence_data)
        
        thread_safe_log("B∆∞·ªõc 5/5: Hu·∫•n luy·ªán m√¥ h√¨nh Meta-Learner...")
        meta_model, _ = model_trainer.train_meta_learner(sequence_data, image_data)
        
        # L∆∞u k·∫øt qu·∫£ hu·∫•n luy·ªán v√†o file (thay v√¨ session_state)
        training_result = {
            "success": True,
            "timestamp": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "data_points": len(data),
            "feature_count": feature_count,
            "training_samples": len(processed_data),
            "class_distribution": {
                "SHORT": int(class_dist.get(0, 0)) if 'target_class' in processed_data.columns and class_dist is not None else 0,
                "NEUTRAL": int(class_dist.get(1, 0)) if 'target_class' in processed_data.columns and class_dist is not None else 0,
                "LONG": int(class_dist.get(2, 0)) if 'target_class' in processed_data.columns and class_dist is not None else 0
            },
            "model_performance": {
                "lstm": float(lstm_history.get('val_accuracy', [-1])[-1]),
                "transformer": float(transformer_history.get('val_accuracy', [-1])[-1]),
                "cnn": float(cnn_history.get('val_accuracy', [-1])[-1]),
                "historical_similarity": 0.65,
                "meta_learner": 0.85
            }
        }
        with open('training_result.json', 'w') as f:
            json.dump(training_result, f)
        
        # Th√¥ng b√°o ƒë√£ hu·∫•n luy·ªán th√†nh c√¥ng - set flag cho main thread
        with open('training_completed.txt', 'w') as f:
            f.write('success')
        
        thread_safe_log("T·∫•t c·∫£ c√°c m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán th√†nh c√¥ng!")
        return True
    except Exception as e:
        thread_safe_log(f"L·ªñI trong qu√° tr√¨nh hu·∫•n luy·ªán: {str(e)}")
        # L∆∞u th√¥ng tin l·ªói v√†o file
        training_result = {
            "success": False,
            "timestamp": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "error": str(e)
        }
        with open('training_result.json', 'w') as f:
            json.dump(training_result, f)
            
        # Th√¥ng b√°o l·ªói cho main thread
        with open('training_completed.txt', 'w') as f:
            f.write('error')
            
        return False
```

#### B∆∞·ªõc 4: T·∫°o h√†m ki·ªÉm tra k·∫øt qu·∫£ hu·∫•n luy·ªán:

```python
def get_training_result():
    """ƒê·ªçc k·∫øt qu·∫£ hu·∫•n luy·ªán t·ª´ file"""
    if os.path.exists('training_result.json'):
        try:
            with open('training_result.json', 'r') as f:
                result = json.load(f)
            return result
        except Exception:
            return None
    return None

def is_training_complete():
    """Ki·ªÉm tra xem qu√° tr√¨nh hu·∫•n luy·ªán ƒë√£ ho√†n t·∫•t ch∆∞a"""
    if os.path.exists('training_completed.txt'):
        try:
            with open('training_completed.txt', 'r') as f:
                status = f.read().strip()
            # X√≥a file ƒë·ªÉ tr√°nh ƒë·ªçc l·∫°i tr·∫°ng th√°i c≈©
            os.remove('training_completed.txt')
            return status
        except Exception:
            return None
    return None
```

#### B∆∞·ªõc 5: Ki·ªÉm tra k·∫øt qu·∫£ hu·∫•n luy·ªán trong main thread:

Th√™m ƒëo·∫°n code sau v√†o ph·∫ßn kh·ªüi t·∫°o ·ª©ng d·ª•ng ho·∫∑c n∆°i th√≠ch h·ª£p trong main thread:

```python
# Ki·ªÉm tra k·∫øt qu·∫£ hu·∫•n luy·ªán t·ª´ background thread
training_status = is_training_complete()
if training_status == 'success':
    # ƒê·ªçc k·∫øt qu·∫£ hu·∫•n luy·ªán t·ª´ file
    training_result = get_training_result()
    if training_result and training_result.get('success', False):
        # C·∫≠p nh·∫≠t session_state v·ªõi k·∫øt qu·∫£ hu·∫•n luy·ªán
        st.session_state.model_trained = True
        st.session_state.training_info = training_result
        # Hi·ªÉn th·ªã th√¥ng b√°o th√†nh c√¥ng
        st.success("üéâ M√¥ h√¨nh AI ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán th√†nh c√¥ng!")
        # C·∫≠p nh·∫≠t UI
        st.rerun()
elif training_status == 'error':
    # ƒê·ªçc th√¥ng tin l·ªói
    training_result = get_training_result()
    if training_result:
        # Hi·ªÉn th·ªã th√¥ng b√°o l·ªói
        error_msg = training_result.get('error', 'Unknown error')
        st.error(f"‚ùå L·ªói hu·∫•n luy·ªán m√¥ h√¨nh: {error_msg}")
```

## Ph·∫ßn b·ªï sung:

### Hi·ªÉn th·ªã nh·∫≠t k√Ω hu·∫•n luy·ªán t·ª´ file:

Thay th·∫ø ƒëo·∫°n code hi·ªÉn th·ªã training logs:

```python
# Hi·ªÉn th·ªã training logs t·ª´ file thay v√¨ session_state
from utils.thread_safe_logging import read_logs_from_file

# ƒê·ªçc logs t·ª´ file
training_logs = read_logs_from_file("training_logs.txt", max_lines=100)

# Hi·ªÉn th·ªã logs
if training_logs:
    # Format the logs with color highlighting
    formatted_logs = []
    for log in training_logs:
        if "ERROR" in log or "error" in log or "L·ªñI" in log:
            formatted_logs.append(f'<span style="color: red;">{log}</span>')
        elif "WARNING" in log or "warning" in log:
            formatted_logs.append(f'<span style="color: yellow;">{log}</span>')
        elif "SUCCESS" in log or "success" in log or "th√†nh c√¥ng" in log:
            formatted_logs.append(f'<span style="color: lime;">{log}</span>')
        elif "INFO" in log or "info" in log:
            formatted_logs.append(f'<span style="color: #0f9;">{log}</span>')
        else:
            formatted_logs.append(log)
    
    log_html = "<div class='training-log-container'>"
    for log in formatted_logs:
        log_html += f"{log}<br>"
    log_html += "</div>"
    
    st.markdown(log_html, unsafe_allow_html=True)
else:
    st.info("Ch∆∞a c√≥ nh·∫≠t k√Ω hu·∫•n luy·ªán n√†o ƒë∆∞·ª£c ghi l·∫°i.")
```

## C√°c b∆∞·ªõc tri·ªÉn khai:

1. Sao ch√©p file thread_safe_logging.py v√†o th∆∞ m·ª•c utils/
2. S·ª≠a h√†m train_models, train_models_background v√† th√™m c√°c h√†m m·ªõi
3. S·ª≠a l·ªói pandas style.map
4. T·∫°o file training_logs.txt tr∆∞·ªõc khi ch·∫°y: `touch training_logs.txt && chmod 666 training_logs.txt`
5. Kh·ªüi ƒë·ªông l·∫°i ·ª©ng d·ª•ng