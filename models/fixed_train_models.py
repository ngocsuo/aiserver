"""
Phi√™n b·∫£n ƒë√£ s·ª≠a l·ªói cho continuous_trainer.py
L·ªói: too many values to unpack (expected 2)
"""
import os
import sys
import time
import logging
import threading
import queue
from datetime import datetime, timedelta
import calendar
import numpy as np
import pandas as pd

import config
from utils.thread_safe_logging import thread_safe_log
from utils.data_collector import create_data_collector
from utils.data_processor import DataProcessor
from models.model_trainer import ModelTrainer

# Thi·∫øt l·∫≠p logger
logger = logging.getLogger(__name__)

def _train_for_timeframe(self, timeframe):
    """
    Train models for a specific timeframe.
    
    Args:
        timeframe (str): Timeframe to train for (e.g., "1m", "5m")
    """
    try:
        # Import dependencies here to avoid circular imports
        from utils.data_collector import create_data_collector
        from utils.data_processor import DataProcessor
        from models.model_trainer import ModelTrainer
        from utils.thread_safe_logging import thread_safe_log
        
        # Create necessary objects
        data_collector = create_data_collector()
        data_processor = DataProcessor()
        model_trainer = ModelTrainer()
        
        # Collect data
        self._add_log(f"Collecting data for {timeframe}")
        thread_safe_log(f"Collecting data for {timeframe}")
        
        if hasattr(config, 'HISTORICAL_START_DATE') and config.HISTORICAL_START_DATE:
            # For historical training
            data = data_collector.collect_historical_data(
                timeframe=timeframe,
                start_date=config.HISTORICAL_START_DATE
            )
        else:
            # For recent data only
            data = data_collector.collect_historical_data(
                timeframe=timeframe, 
                limit=config.LOOKBACK_PERIODS
            )
        
        if data is None or len(data) == 0:
            self._add_log(f"No data available for {timeframe}")
            thread_safe_log(f"No data available for {timeframe}")
            return
            
        self._add_log(f"Collected {len(data)} candles for {timeframe}")
        thread_safe_log(f"Collected {len(data)} candles for {timeframe}")
        
        # Process data
        self._add_log(f"Processing data for {timeframe}")
        thread_safe_log(f"Processing data for {timeframe}")
        processed_data = data_processor.process_data(data)
        
        # Prepare sequence data
        self._add_log(f"Preparing sequence data for {timeframe}")
        thread_safe_log(f"Preparing sequence data for {timeframe}")
        sequence_data = data_processor.prepare_sequence_data(processed_data)
        
        # Prepare image data
        self._add_log(f"Preparing image data for {timeframe}")
        thread_safe_log(f"Preparing image data for {timeframe}")
        image_data = data_processor.prepare_cnn_data(processed_data)
        
        # Train models
        self._add_log(f"Training models for {timeframe}")
        thread_safe_log(f"Training models for {timeframe}")
        
        # QUAN TR·ªåNG: S·ª¨A L·ªñI ·ªû ƒê√ÇY
        try:
            # X·ª≠ l√Ω l·ªói n·∫øu h√†m train_all_models tr·∫£ v·ªÅ tuple ho·∫∑c nhi·ªÅu gi√° tr·ªã
            result = model_trainer.train_all_models(sequence_data, image_data, timeframe=timeframe)
            # Ki·ªÉm tra xem k·∫øt qu·∫£ c√≥ ph·∫£i l√† tuple v·ªõi nhi·ªÅu gi√° tr·ªã kh√¥ng
            if isinstance(result, tuple):
                # N·∫øu l√† tuple, l·∫•y ph·∫ßn t·ª≠ ƒë·∫ßu ti√™n (models)
                models = result[0]
            else:
                # N·∫øu kh√¥ng, s·ª≠ d·ª•ng k·∫øt qu·∫£ tr·ª±c ti·∫øp
                models = result
        except ValueError as e:
            if "too many values to unpack" in str(e):
                # Ghi log l·ªói v√† th·ª≠ l·∫°i v·ªõi c√°ch kh√°c
                thread_safe_log(f"L·ªói khi unpack gi√° tr·ªã: {e}. Th·ª≠ l·∫°i v·ªõi c√°ch l·∫•y ph·∫ßn t·ª≠ ƒë·∫ßu ti√™n.")
                result = model_trainer.train_all_models(sequence_data, image_data, timeframe=timeframe)
                # √âp ki·ªÉu k·∫øt qu·∫£ v·ªÅ list v√† l·∫•y ph·∫ßn t·ª≠ ƒë·∫ßu ti√™n
                models = list(result)[0] if isinstance(result, (list, tuple)) else result
            else:
                # N·∫øu l√† l·ªói ValueError kh√°c, n√©m l·∫°i ngo·∫°i l·ªá
                raise
        
        if models:
            self._add_log(f"Models trained successfully for {timeframe}")
            thread_safe_log(f"Models trained successfully for {timeframe}")
            return models
        else:
            self._add_log(f"No models trained for {timeframe}")
            thread_safe_log(f"No models trained for {timeframe}")
            return None
            
    except Exception as e:
        self._add_log(f"Error training for timeframe {timeframe}: {e}")
        thread_safe_log(f"Error training for timeframe {timeframe}: {e}")
        logger.error(f"Error training for timeframe {timeframe}: {e}")
        raise

def _execute_training(self, force=False):
    """
    Execute the actual training process.
    
    Args:
        force (bool): If True, force training regardless of whether enough new data is available
    """
    if self.training_in_progress:
        logger.warning("Training already in progress, skipping")
        return
        
    try:
        self.training_in_progress = True
        start_time = datetime.now()
        
        logger.info(f"Starting training process at {start_time}")
        thread_safe_log(f"B·∫Øt ƒë·∫ßu qu√° tr√¨nh hu·∫•n luy·ªán l√∫c {start_time}")
        
        # Check if we have enough new data to justify retraining
        if not force and self.new_data_count < config.MINIMUM_NEW_DATA_POINTS:
            logger.info(f"Not enough new data ({self.new_data_count} points) for retraining, minimum required: {config.MINIMUM_NEW_DATA_POINTS}")
            self.training_in_progress = False
            return
            
        # Train by monthly chunks if enabled
        if config.CHUNK_BY_MONTHS and self.chunk_start_dates:
            result = self._train_by_monthly_chunks()
            # Th√™m x·ª≠ l√Ω k·∫øt qu·∫£ n·∫øu c·∫ßn thi·∫øt
        else:
            result = self._train_with_all_data()
            # Th√™m x·ª≠ l√Ω k·∫øt qu·∫£ n·∫øu c·∫ßn thi·∫øt
            
        # Record training event
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        self.last_training_time = end_time
        self.training_history.append({
            "start_time": start_time.strftime("%Y-%m-%d %H:%M:%S"),
            "end_time": end_time.strftime("%Y-%m-%d %H:%M:%S"),
            "duration_seconds": duration,
            "data_points": self.new_data_count,
            "forced": force
        })
        
        # Reset new data counter
        self.new_data_count = 0
        
        # Log completion with duration
        mins = int(duration // 60)
        secs = int(duration % 60)
        time_str = f"{mins} ph√∫t {secs} gi√¢y" if mins > 0 else f"{secs} gi√¢y"
        self._add_log(f"‚úÖ Qu√° tr√¨nh hu·∫•n luy·ªán ho√†n t·∫•t trong {time_str}")
        thread_safe_log(f"Qu√° tr√¨nh hu·∫•n luy·ªán ho√†n t·∫•t trong {time_str}")
        
        # Calculate next training time
        next_time = end_time + timedelta(seconds=30*60)  # 30 minutes
        self._add_log(f"‚è±Ô∏è ƒê·ª£t hu·∫•n luy·ªán ti·∫øp theo d·ª± ki·∫øn: {next_time.strftime('%H:%M:%S')}")
        thread_safe_log(f"ƒê·ª£t hu·∫•n luy·ªán ti·∫øp theo d·ª± ki·∫øn: {next_time.strftime('%H:%M:%S')}")
        
        logger.info(f"Training process completed in {duration:.1f} seconds")
        
    except Exception as e:
        logger.error(f"Error during training execution: {e}")
        thread_safe_log(f"L·ªói trong qu√° tr√¨nh hu·∫•n luy·ªán: {e}")
        self._add_log(f"‚ùå L·ªói hu·∫•n luy·ªán: {str(e)}")
    finally:
        self.training_in_progress = False
        
def _train_with_all_data(self):
    """Train models using all data at once."""
    logger.info("Training with all data at once")
    
    try:
        # Collect all historical data
        raw_data = None
        
        self._add_log("üîÑ ƒêang thu th·∫≠p d·ªØ li·ªáu l·ªãch s·ª≠...")
        thread_safe_log("ƒêang thu th·∫≠p d·ªØ li·ªáu l·ªãch s·ª≠...")
        
        if hasattr(config, 'HISTORICAL_START_DATE') and config.HISTORICAL_START_DATE:
            raw_data = self.data_collector.collect_historical_data(
                timeframe=config.TIMEFRAMES["primary"],
                start_date=config.HISTORICAL_START_DATE
            )
        else:
            raw_data = self.data_collector.collect_historical_data(
                timeframe=config.TIMEFRAMES["primary"],
                limit=config.LOOKBACK_PERIODS
            )
            
        if raw_data is not None and not raw_data.empty:
            # Process the data
            self._add_log(f"üîß ƒêang x·ª≠ l√Ω {len(raw_data)} ƒëi·ªÉm d·ªØ li·ªáu l·ªãch s·ª≠...")
            thread_safe_log(f"ƒêang x·ª≠ l√Ω {len(raw_data)} ƒëi·ªÉm d·ªØ li·ªáu l·ªãch s·ª≠...")
            processed_data = self.data_processor.process_data(raw_data)
            
            # Prepare data for different model types
            self._add_log("üìä ƒêang chu·∫©n b·ªã d·ªØ li·ªáu ƒë·∫ßu v√†o cho c√°c m√¥ h√¨nh...")
            thread_safe_log("ƒêang chu·∫©n b·ªã d·ªØ li·ªáu ƒë·∫ßu v√†o cho c√°c m√¥ h√¨nh...")
            sequence_data = self.data_processor.prepare_sequence_data(processed_data)
            image_data = self.data_processor.prepare_cnn_data(processed_data)
            
            # Train all models
            self._add_log(f"üß† B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán c√°c m√¥ h√¨nh v·ªõi {len(processed_data)} ƒëi·ªÉm d·ªØ li·ªáu")
            thread_safe_log(f"B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán c√°c m√¥ h√¨nh v·ªõi {len(processed_data)} ƒëi·ªÉm d·ªØ li·ªáu")
            
            # QUAN TR·ªåNG: S·ª¨A L·ªñI ·ªû ƒê√ÇY
            try:
                # X·ª≠ l√Ω l·ªói n·∫øu h√†m train_all_models tr·∫£ v·ªÅ tuple ho·∫∑c nhi·ªÅu gi√° tr·ªã
                result = self.model_trainer.train_all_models(sequence_data, image_data)
                # Ki·ªÉm tra xem k·∫øt qu·∫£ c√≥ ph·∫£i l√† tuple v·ªõi nhi·ªÅu gi√° tr·ªã kh√¥ng
                if isinstance(result, tuple):
                    # N·∫øu l√† tuple, l·∫•y ph·∫ßn t·ª≠ ƒë·∫ßu ti√™n (models)
                    models = result[0]
                else:
                    # N·∫øu kh√¥ng, s·ª≠ d·ª•ng k·∫øt qu·∫£ tr·ª±c ti·∫øp
                    models = result
            except ValueError as e:
                if "too many values to unpack" in str(e):
                    # Ghi log l·ªói v√† th·ª≠ l·∫°i v·ªõi c√°ch kh√°c
                    thread_safe_log(f"L·ªói khi unpack gi√° tr·ªã: {e}. Th·ª≠ l·∫°i v·ªõi c√°ch l·∫•y ph·∫ßn t·ª≠ ƒë·∫ßu ti√™n.")
                    result = self.model_trainer.train_all_models(sequence_data, image_data)
                    # √âp ki·ªÉu k·∫øt qu·∫£ v·ªÅ list v√† l·∫•y ph·∫ßn t·ª≠ ƒë·∫ßu ti√™n
                    models = list(result)[0] if isinstance(result, (list, tuple)) else result
                else:
                    # N·∫øu l√† l·ªói ValueError kh√°c, n√©m l·∫°i ngo·∫°i l·ªá
                    raise
            
            self._add_log(f"‚úÖ ƒê√£ hu·∫•n luy·ªán th√†nh c√¥ng {len(models) if models else 0} m√¥ h√¨nh")
            thread_safe_log(f"ƒê√£ hu·∫•n luy·ªán th√†nh c√¥ng {len(models) if models else 0} m√¥ h√¨nh")
            logger.info(f"Trained {len(models) if models else 0} models with {len(processed_data)} data points")
            
            return models
        else:
            self._add_log("‚ùå Kh√¥ng th·ªÉ thu th·∫≠p d·ªØ li·ªáu l·ªãch s·ª≠ cho vi·ªác hu·∫•n luy·ªán")
            thread_safe_log("Kh√¥ng th·ªÉ thu th·∫≠p d·ªØ li·ªáu l·ªãch s·ª≠ cho vi·ªác hu·∫•n luy·ªán")
            logger.error("No data collected for training")
            return None
            
    except Exception as e:
        self._add_log(f"‚ùå L·ªói hu·∫•n luy·ªán: {str(e)}")
        thread_safe_log(f"L·ªói hu·∫•n luy·ªán: {str(e)}")
        logger.error(f"Error training with all data: {e}")
        return None